{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c9498f-b1c2-44e7-a8c1-46a0176e3c5e",
   "metadata": {},
   "source": [
    "\n",
    "### U-Caps\n",
    "* No CV\n",
    "* OneEpoch\n",
    "* Results Showing for both Train and Test\n",
    "* **All Performance metrics showing for each Batch during Run!**\n",
    "  * This feature is not provided by Keras! I recalled the log using *MetricsCallback*!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c62c380b-9fca-4cea-a742-6ced15031236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jaber\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "1/723 ━━━━━━━━━━━━━━━━━━━━ 17:18:51 - 60s/step\n",
      "Accuracy: 0.7807 - Precision: 0.0081 - Recall: 0.2152 - Specificity: 0.7854 - F1: 0.0156 - Loss: 1.6770\n",
      "\n",
      "2/723 ━━━━━━━━━━━━━━━━━━━━ 17:19:32 - 60s/step\n",
      "Accuracy: 0.8876 - Precision: 0.0040 - Recall: 0.1076 - Specificity: 0.8927 - F1: 0.0078 - Loss: 1.6754\n",
      "\n",
      "3/723 ━━━━━━━━━━━━━━━━━━━━ 17:20:25 - 60s/step\n",
      "Accuracy: 0.9248 - Precision: 0.0027 - Recall: 0.0717 - Specificity: 0.9285 - F1: 0.0052 - Loss: 1.6700\n",
      "\n",
      "4/723 ━━━━━━━━━━━━━━━━━━━━ 17:21:07 - 60s/step\n",
      "Accuracy: 0.9426 - Precision: 0.0020 - Recall: 0.0538 - Specificity: 0.9464 - F1: 0.0039 - Loss: 1.6321\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 237\u001b[0m\n\u001b[0;32m    234\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mcombined_dice_bce_loss, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, custom_precision, custom_recall, custom_f1, custom_specificity])\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# Train the model with the custom callback (verbose=0 to avoid duplicate output)\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_generator, steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_df) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Train for 1 epoch\u001b[39;00m\n\u001b[0;32m    238\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mtest_generator, validation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_df) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size,\n\u001b[0;32m    239\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[MetricsCallback()], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# Evaluate on the train set\u001b[39;00m\n\u001b[0;32m    242\u001b[0m train_generator_eval \u001b[38;5;241m=\u001b[39m data_generator(train_image_dir, train_df, img_size, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Directories for SIIM-ACR Pneumothorax Segmentation dataset\n",
    "train_image_dir = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\SIIM-ACR Pneumothorax Segmentation\\archive\\pneumothorax\\dicom-images-train'\n",
    "test_image_dir = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\SIIM-ACR Pneumothorax Segmentation\\archive\\pneumothorax\\dicom-images-test'\n",
    "train_csv_path = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\SIIM-ACR Pneumothorax Segmentation\\archive\\pneumothorax\\train-rle.csv'\n",
    "\n",
    "img_size = (256, 256)\n",
    "\n",
    "# Load the combined CSV that contains both train and test mask information\n",
    "combined_df = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Split into training and test sets based on the availability of the image files\n",
    "train_df = combined_df[combined_df['ImageId'].apply(lambda x: os.path.exists(os.path.join(train_image_dir, x + '.dcm')))]\n",
    "test_df = combined_df[combined_df['ImageId'].apply(lambda x: os.path.exists(os.path.join(test_image_dir, x + '.dcm')))]\n",
    "\n",
    "# Define the rle2mask function here instead of importing from mask_functions\n",
    "def rle2mask(rle, width, height):\n",
    "    mask = np.zeros(width * height, dtype=np.uint8)\n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "    current_position = 0\n",
    "    for start, length in zip(starts, lengths):\n",
    "        current_position += start\n",
    "        mask[current_position:current_position + length] = 255\n",
    "        current_position += length\n",
    "    return mask.reshape((height, width))\n",
    "\n",
    "# Data generator to load data in batches\n",
    "def data_generator(image_dir, df, img_size, batch_size=16):\n",
    "    while True:\n",
    "        df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "        for start in range(0, len(df_shuffled), batch_size):\n",
    "            end = min(start + batch_size, len(df_shuffled))\n",
    "            batch_df = df_shuffled.iloc[start:end]\n",
    "\n",
    "            images = []\n",
    "            masks = []\n",
    "\n",
    "            for index, row in batch_df.iterrows():\n",
    "                img_id = row['ImageId']\n",
    "                img_path = os.path.join(image_dir, img_id + '.dcm')\n",
    "\n",
    "                dicom_data = pydicom.dcmread(img_path)\n",
    "                img = dicom_data.pixel_array\n",
    "\n",
    "                img = cv2.resize(img, img_size)\n",
    "                img = img / 255.0  # Normalize image to range 0-1\n",
    "\n",
    "                # Check if there is a mask\n",
    "                if pd.isna(row['EncodedPixels']):\n",
    "                    mask = np.zeros(img_size)  # No pneumothorax, empty mask\n",
    "                else:\n",
    "                    mask = rle2mask(row['EncodedPixels'], dicom_data.Rows, dicom_data.Columns)\n",
    "                    mask = cv2.resize(mask, img_size)\n",
    "                    mask = mask / 255.0  # Normalize mask to range 0-1\n",
    "\n",
    "                images.append(np.expand_dims(img, axis=-1))  # Add channel dimension to the image\n",
    "                masks.append(np.expand_dims(mask, axis=-1))  # Add channel dimension to the mask\n",
    "\n",
    "            yield np.array(images), np.array(masks)\n",
    "\n",
    "# Capsule Layer with Dynamic Routing\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def squash(vectors, axis=-1):\n",
    "    \"\"\"Squashing function to ensure output vectors' lengths are between 0 and 1\"\"\"\n",
    "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + tf.keras.backend.epsilon())\n",
    "    return scale * vectors\n",
    "\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    def __init__(self, num_capsules, dim_capsule, num_routing=3, **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsules = num_capsules\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.num_routing = num_routing\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=[input_shape[-1], self.num_capsules * self.dim_capsule],\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.reshape(inputs, [-1, inputs.shape[1] * inputs.shape[2], inputs.shape[3]])\n",
    "        u_hat = tf.einsum('...ij,jk->...ik', inputs, self.W)\n",
    "        u_hat = tf.reshape(u_hat, [-1, inputs.shape[1], self.num_capsules, self.dim_capsule])\n",
    "        \n",
    "        b = tf.zeros(shape=[tf.shape(inputs)[0], inputs.shape[1], self.num_capsules])\n",
    "        for i in range(self.num_routing):\n",
    "            c = tf.nn.softmax(b, axis=-1)\n",
    "            s = tf.reduce_sum(c[..., tf.newaxis] * u_hat, axis=1)\n",
    "            v = squash(s)\n",
    "            if i < self.num_routing - 1:\n",
    "                b += tf.reduce_sum(u_hat * v[:, tf.newaxis, :, :], axis=-1)\n",
    "        return v\n",
    "\n",
    "# U-Net with Capsule Network Layers and Dynamic Routing\n",
    "def unet_capsule_model(input_size=(256, 256, 1)):\n",
    "    inputs = tf.keras.layers.Input(input_size)\n",
    "    \n",
    "    # Contracting Path with Capsules\n",
    "    c1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = CapsuleLayer(num_capsules=8, dim_capsule=16)(c1)\n",
    "    c1_flattened = tf.keras.layers.Flatten()(c1)  # Flatten the capsule output\n",
    "    c1_reshaped = tf.keras.layers.Dense(256*256, activation='relu')(c1_flattened)  # Fully connected layer to reshape\n",
    "    c1_reshaped = tf.keras.layers.Reshape((256, 256, 1))(c1_reshaped)  # Reshape to 4D\n",
    "    p1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c1_reshaped)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = CapsuleLayer(num_capsules=16, dim_capsule=32)(c2)\n",
    "    c2_flattened = tf.keras.layers.Flatten()(c2)\n",
    "    c2_reshaped = tf.keras.layers.Dense(128*128, activation='relu')(c2_flattened)\n",
    "    c2_reshaped = tf.keras.layers.Reshape((128, 128, 1))(c2_reshaped)\n",
    "    p2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c2_reshaped)\n",
    "    \n",
    "    c3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
    "    c3 = CapsuleLayer(num_capsules=32, dim_capsule=64)(c3)\n",
    "    c3_flattened = tf.keras.layers.Flatten()(c3)\n",
    "    c3_reshaped = tf.keras.layers.Dense(64*64, activation='relu')(c3_flattened)\n",
    "    c3_reshaped = tf.keras.layers.Reshape((64, 64, 1))(c3_reshaped)\n",
    "    p3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c3_reshaped)\n",
    "    \n",
    "    # Bottleneck\n",
    "    b = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(p3)\n",
    "    b = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(b)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u1 = tf.keras.layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(b)\n",
    "    u1 = tf.keras.layers.concatenate([u1, c3_reshaped])\n",
    "    c4 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(u1)\n",
    "    c4 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(c4)\n",
    "    \n",
    "    u2 = tf.keras.layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(c4)\n",
    "    u2 = tf.keras.layers.concatenate([u2, c2_reshaped])\n",
    "    c5 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(u2)\n",
    "    c5 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(c5)\n",
    "    \n",
    "    u3 = tf.keras.layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(c5)\n",
    "    u3 = tf.keras.layers.concatenate([u3, c1_reshaped])\n",
    "    c6 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(u3)\n",
    "    c6 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(c6)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(c6)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Dice and Binary Crossentropy combined loss function\n",
    "def combined_dice_bce_loss(y_true, y_pred):\n",
    "    y_true_f = tf.cast(tf.keras.backend.flatten(y_true), dtype='float32')\n",
    "    y_pred_f = tf.cast(tf.keras.backend.flatten(y_pred), dtype='float32')\n",
    "    \n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    dice_loss = 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n",
    "    \n",
    "    bce_loss = tf.keras.losses.binary_crossentropy(y_true_f, y_pred_f)\n",
    "    \n",
    "    return dice_loss + bce_loss\n",
    "\n",
    "# Custom metrics for Keras (with data type casting to fix type mismatch)\n",
    "def custom_precision(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, dtype='float32')\n",
    "    y_pred = tf.round(tf.cast(y_pred, dtype='float32'))\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred)\n",
    "    predicted_positives = tf.reduce_sum(y_pred)\n",
    "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
    "    return precision\n",
    "\n",
    "def custom_recall(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, dtype='float32')\n",
    "    y_pred = tf.round(tf.cast(y_pred, dtype='float32'))\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred)\n",
    "    possible_positives = tf.reduce_sum(y_true)\n",
    "    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
    "    return recall\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    precision = custom_precision(y_true, y_pred)\n",
    "    recall = custom_recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
    "\n",
    "def custom_specificity(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, dtype='float32')\n",
    "    y_pred = tf.round(tf.cast(y_pred, dtype='float32'))\n",
    "    true_negatives = tf.reduce_sum((1 - y_true) * (1 - y_pred))\n",
    "    possible_negatives = tf.reduce_sum(1 - y_true)\n",
    "    specificity = true_negatives / (possible_negatives + tf.keras.backend.epsilon())\n",
    "    return specificity\n",
    "\n",
    "# Custom callback to print more metrics at each batch in the exact format you requested\n",
    "class MetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.batch_counter = 1  # Initialize the batch counter\n",
    "    \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        \n",
    "        # Time formatting for current step\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        # Print the metrics with proper formatting\n",
    "        print(f\"{self.batch_counter}/723 ━━━━━━━━━━━━━━━━━━━━ {current_time} - 60s/step\")\n",
    "        print(f\"Accuracy: {accuracy:.4f} - Precision: {precision:.4f} - Recall: {recall:.4f} - Specificity: {specificity:.4f} - F1: {f1:.4f} - Loss: {loss:.4f}\\n\")\n",
    "        \n",
    "        # Increment batch counter\n",
    "        self.batch_counter += 1\n",
    "\n",
    "# Batch size for data generator\n",
    "batch_size = 16\n",
    "\n",
    "# Train generator and test generator\n",
    "train_generator = data_generator(train_image_dir, train_df, img_size, batch_size=batch_size)\n",
    "test_generator = data_generator(test_image_dir, test_df, img_size, batch_size=batch_size)\n",
    "\n",
    "# Model training and testing\n",
    "model = unet_capsule_model()\n",
    "model.compile(optimizer='adam', loss=combined_dice_bce_loss, metrics=['accuracy', custom_precision, custom_recall, custom_f1, custom_specificity])\n",
    "\n",
    "# Train the model with the custom callback (verbose=0 to avoid duplicate output)\n",
    "history = model.fit(train_generator, steps_per_epoch=len(train_df) // batch_size, epochs=1,  # Train for 1 epoch\n",
    "                    validation_data=test_generator, validation_steps=len(test_df) // batch_size,\n",
    "                    callbacks=[MetricsCallback()], verbose=0)\n",
    "\n",
    "# Evaluate on the train set\n",
    "train_generator_eval = data_generator(train_image_dir, train_df, img_size, batch_size=batch_size)\n",
    "y_train_pred = model.predict(train_generator_eval, steps=len(train_df) // batch_size)\n",
    "y_train_true = np.array([mask for _, mask in train_generator_eval]).astype(np.uint8)\n",
    "y_train_pred = (y_train_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for training\n",
    "conf_matrix_train = confusion_matrix(y_train_true.flatten(), y_train_pred.flatten())\n",
    "sns.heatmap(conf_matrix_train, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix for Train\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = model.predict(test_generator, steps=len(test_df) // batch_size)\n",
    "y_test_true = np.array([mask for _, mask in test_generator]).astype(np.uint8)\n",
    "y_test_pred = (y_test_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for testing\n",
    "conf_matrix_test = confusion_matrix(y_test_true.flatten(), y_test_pred.flatten())\n",
    "sns.heatmap(conf_matrix_test, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix for Test\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization: Show input image, true mask, and predicted mask for a few samples for both train and test\n",
    "def visualize_predictions(generator, true_masks, pred_masks, title):\n",
    "    for i in range(3):  # Visualize first 3 predictions\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        X = next(generator)[0]\n",
    "        \n",
    "        ax[0].imshow(X[i].squeeze(), cmap='gray')\n",
    "        ax[0].set_title('Input Image')\n",
    "\n",
    "        ax[1].imshow(true_masks[i].squeeze(), cmap='gray')\n",
    "        ax[1].set_title('True Mask')\n",
    "\n",
    "        ax[2].imshow(pred_masks[i].squeeze(), cmap='gray')\n",
    "        ax[2].set_title('Predicted Mask')\n",
    "\n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "# Visualize predictions for training set\n",
    "visualize_predictions(train_generator_eval, y_train_true, y_train_pred, \"Train Set Predictions\")\n",
    "\n",
    "# Visualize predictions for testing set\n",
    "visualize_predictions(test_generator, y_test_true, y_test_pred, \"Test Set Predictions\")\n",
    "\n",
    "# Performance report for training set\n",
    "train_accuracy = accuracy_score(y_train_true.flatten(), y_train_pred.flatten())\n",
    "train_recall = recall_score(y_train_true.flatten(), y_train_pred.flatten())\n",
    "train_precision = precision_score(y_train_true.flatten(), y_train_pred.flatten())\n",
    "train_f1 = f1_score(y_train_true.flatten(), y_train_pred.flatten())\n",
    "train_tn, train_fp, train_fn, train_tp = confusion_matrix(y_train_true.flatten(), y_train_pred.flatten()).ravel()\n",
    "train_specificity = train_tn / (train_tn + train_fp)\n",
    "\n",
    "print(f'Training Set Results:')\n",
    "print(f'Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Recall (Sensitivity): {train_recall:.4f}')\n",
    "print(f'Precision: {train_precision:.4f}')\n",
    "print(f'F1 Score: {train_f1:.4f}')\n",
    "print(f'Specificity: {train_specificity:.4f}')\n",
    "\n",
    "# Performance report for testing set\n",
    "test_accuracy = accuracy_score(y_test_true.flatten(), y_test_pred.flatten())\n",
    "test_recall = recall_score(y_test_true.flatten(), y_test_pred.flatten())\n",
    "test_precision = precision_score(y_test_true.flatten(), y_test_pred.flatten())\n",
    "test_f1 = f1_score(y_test_true.flatten(), y_test_pred.flatten())\n",
    "test_tn, test_fp, test_fn, test_tp = confusion_matrix(y_test_true.flatten(), y_test_pred.flatten()).ravel()\n",
    "test_specificity = test_tn / (test_tn + test_fp)\n",
    "\n",
    "print(f'Testing Set Results:')\n",
    "print(f'Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Recall (Sensitivity): {test_recall:.4f}')\n",
    "print(f'Precision: {test_precision:.4f}')\n",
    "print(f'F1 Score: {test_f1:.4f}')\n",
    "print(f'Specificity: {test_specificity:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35a920-956d-44d6-aeb4-dac17c10e6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c36122-311e-41b9-9463-d38a2aab2e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5258b-4617-417f-a175-c1ec66ba69bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfea86-6c09-49eb-b161-63c7703dffa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ad043e3-dfe3-4c9f-aebf-87901d38de45",
   "metadata": {},
   "source": [
    "Results show that we have Good Accuracy but High loss! I checked the diagrams and found that this high value for Loss could be due to the Poor performance of the model on Edge (Boundy) detection of segmentations.\n",
    "\n",
    "The model is improved by the followings:\n",
    "* Use Boundary-Aware Loss Functions: Introduce loss functions that emphasize boundary accuracy. Examples include:\n",
    " - Boundary Loss: Directly focus on minimizing the error at object boundaries by computing the distance between predicted and true boundary pixels.\n",
    "\n",
    "* Attention Mechanisms: Incorporate attention layers or attention gates to allow the model to focus on boundary regions more effectively. Attention mechanisms help the model prioritize important features and pixels, like object boundaries, during training.\n",
    "\n",
    "\n",
    "* Edge Detection as Preprocessing: Incorporate an edge detection module (e.g., using Sobel filters or Canny edge detectors) to provide the model with explicit boundary information as input, making it easier for the model to focus on boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef2dc39-180d-4566-b565-cfbc22cb2b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jaber\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "1/723 ━━━━━━━━━━━━━━━━━━━━ 19:53:09 - 60s/step\n",
      "Accuracy: 0.7317 - Precision: 0.0001 - Recall: 0.1695 - Specificity: 0.7317 - F1: 0.0001 - Loss: 1.1988\n",
      "\n",
      "2/723 ━━━━━━━━━━━━━━━━━━━━ 19:54:19 - 60s/step\n",
      "Accuracy: 0.4536 - Precision: 0.0001 - Recall: 0.2324 - Specificity: 0.4536 - F1: 0.0001 - Loss: 1.1431\n",
      "\n",
      "3/723 ━━━━━━━━━━━━━━━━━━━━ 19:55:11 - 60s/step\n",
      "Accuracy: 0.4267 - Precision: 0.0000 - Recall: 0.1685 - Specificity: 0.4267 - F1: 0.0001 - Loss: 1.1049\n",
      "\n",
      "4/723 ━━━━━━━━━━━━━━━━━━━━ 19:56:04 - 60s/step\n",
      "Accuracy: 0.4318 - Precision: 0.0000 - Recall: 0.1317 - Specificity: 0.4319 - F1: 0.0001 - Loss: 1.0809\n",
      "\n",
      "5/723 ━━━━━━━━━━━━━━━━━━━━ 19:56:47 - 60s/step\n",
      "Accuracy: 0.4431 - Precision: 0.0000 - Recall: 0.1053 - Specificity: 0.4432 - F1: 0.0000 - Loss: 1.0661\n",
      "\n",
      "6/723 ━━━━━━━━━━━━━━━━━━━━ 19:57:39 - 60s/step\n",
      "Accuracy: 0.4561 - Precision: 0.0000 - Recall: 0.0878 - Specificity: 0.4561 - F1: 0.0000 - Loss: 1.0562\n",
      "\n",
      "7/723 ━━━━━━━━━━━━━━━━━━━━ 19:58:44 - 60s/step\n",
      "Accuracy: 0.4695 - Precision: 0.0000 - Recall: 0.0752 - Specificity: 0.4695 - F1: 0.0000 - Loss: 1.0489\n",
      "\n",
      "8/723 ━━━━━━━━━━━━━━━━━━━━ 19:59:55 - 60s/step\n",
      "Accuracy: 0.4843 - Precision: 0.0000 - Recall: 0.0658 - Specificity: 0.4843 - F1: 0.0000 - Loss: 1.0433\n",
      "\n",
      "9/723 ━━━━━━━━━━━━━━━━━━━━ 20:01:04 - 60s/step\n",
      "Accuracy: 0.5025 - Precision: 0.0000 - Recall: 0.0585 - Specificity: 0.5026 - F1: 0.0000 - Loss: 1.0389\n",
      "\n",
      "10/723 ━━━━━━━━━━━━━━━━━━━━ 20:02:05 - 60s/step\n",
      "Accuracy: 0.5225 - Precision: 0.0000 - Recall: 0.0527 - Specificity: 0.5226 - F1: 0.0000 - Loss: 1.0353\n",
      "\n",
      "11/723 ━━━━━━━━━━━━━━━━━━━━ 20:03:17 - 60s/step\n",
      "Accuracy: 0.5430 - Precision: 0.0000 - Recall: 0.0479 - Specificity: 0.5430 - F1: 0.0000 - Loss: 1.0324\n",
      "\n",
      "12/723 ━━━━━━━━━━━━━━━━━━━━ 20:04:04 - 60s/step\n",
      "Accuracy: 0.5634 - Precision: 0.0000 - Recall: 0.0439 - Specificity: 0.5635 - F1: 0.0000 - Loss: 1.0300\n",
      "\n",
      "13/723 ━━━━━━━━━━━━━━━━━━━━ 20:05:12 - 60s/step\n",
      "Accuracy: 0.5828 - Precision: 0.0000 - Recall: 0.0405 - Specificity: 0.5829 - F1: 0.0000 - Loss: 1.0280\n",
      "\n",
      "14/723 ━━━━━━━━━━━━━━━━━━━━ 20:06:06 - 60s/step\n",
      "Accuracy: 0.6009 - Precision: 0.0000 - Recall: 0.0380 - Specificity: 0.6010 - F1: 0.0000 - Loss: 1.0262\n",
      "\n",
      "15/723 ━━━━━━━━━━━━━━━━━━━━ 20:07:22 - 60s/step\n",
      "Accuracy: 0.6177 - Precision: 0.0000 - Recall: 0.0355 - Specificity: 0.6178 - F1: 0.0000 - Loss: 1.0246\n",
      "\n",
      "16/723 ━━━━━━━━━━━━━━━━━━━━ 20:08:32 - 60s/step\n",
      "Accuracy: 0.6332 - Precision: 0.0000 - Recall: 0.0332 - Specificity: 0.6332 - F1: 0.0000 - Loss: 1.0233\n",
      "\n",
      "17/723 ━━━━━━━━━━━━━━━━━━━━ 20:09:57 - 60s/step\n",
      "Accuracy: 0.6475 - Precision: 0.0000 - Recall: 0.0313 - Specificity: 0.6476 - F1: 0.0000 - Loss: 1.0220\n",
      "\n",
      "18/723 ━━━━━━━━━━━━━━━━━━━━ 20:11:21 - 60s/step\n",
      "Accuracy: 0.6617 - Precision: 0.0000 - Recall: 0.0296 - Specificity: 0.6618 - F1: 0.0000 - Loss: 1.0209\n",
      "\n",
      "19/723 ━━━━━━━━━━━━━━━━━━━━ 20:12:45 - 60s/step\n",
      "Accuracy: 0.6763 - Precision: 0.0000 - Recall: 0.0323 - Specificity: 0.6763 - F1: 0.0000 - Loss: 1.0199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Directories for SIIM-ACR Pneumothorax Segmentation dataset\n",
    "train_image_dir = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\SIIM-ACR Pneumothorax Segmentation\\archive\\pneumothorax\\dicom-images-train'\n",
    "test_image_dir = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\SIIM-ACR Pneumothorax Segmentation\\archive\\pneumothorax\\dicom-images-test'\n",
    "train_csv_path = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\SIIM-ACR Pneumothorax Segmentation\\archive\\pneumothorax\\train-rle.csv'\n",
    "\n",
    "img_size = (256, 256)\n",
    "\n",
    "# Load the combined CSV that contains both train and test mask information\n",
    "combined_df = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Split into training and test sets based on the availability of the image files\n",
    "train_df = combined_df[combined_df['ImageId'].apply(lambda x: os.path.exists(os.path.join(train_image_dir, x + '.dcm')))]\n",
    "test_df = combined_df[combined_df['ImageId'].apply(lambda x: os.path.exists(os.path.join(test_image_dir, x + '.dcm')))]\n",
    "\n",
    "# Define the rle2mask function\n",
    "def rle2mask(rle, width, height):\n",
    "    mask = np.zeros(width * height, dtype=np.uint8)\n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2] - 1  # Adjust start positions\n",
    "    lengths = array[1::2]\n",
    "    for start, length in zip(starts, lengths):\n",
    "        mask[int(start):int(start + length)] = 255\n",
    "    return mask.reshape((height, width)).T  # Transpose to match the image orientation\n",
    "\n",
    "# Sobel edge detection for preprocessing\n",
    "def sobel_edge_detection(image):\n",
    "    image_rank = len(image.shape)\n",
    "    if image_rank == 2:\n",
    "        # Shape is [height, width]\n",
    "        image = tf.expand_dims(image, axis=-1)  # Add channel dimension\n",
    "        image = tf.expand_dims(image, axis=0)   # Add batch dimension\n",
    "        edges = tf.image.sobel_edges(image)     # Output shape: [1, height, width, 1, 2]\n",
    "        edges = tf.sqrt(tf.reduce_sum(tf.square(edges), axis=-1))  # Shape: [1, height, width, 1]\n",
    "        edges = tf.squeeze(edges, axis=[0, -1])  # Remove batch and channel dimensions\n",
    "        edges = edges / (tf.reduce_max(edges) + tf.keras.backend.epsilon())  # Normalize to 0-1\n",
    "    elif image_rank == 3:\n",
    "        # Shape is [height, width, channels]\n",
    "        image = tf.expand_dims(image, axis=0)   # Add batch dimension\n",
    "        edges = tf.image.sobel_edges(image)     # Output shape: [1, height, width, channels, 2]\n",
    "        edges = tf.sqrt(tf.reduce_sum(tf.square(edges), axis=-1))  # Shape: [1, height, width, channels]\n",
    "        edges = tf.squeeze(edges, axis=0)       # Remove batch dimension\n",
    "        edges = edges / (tf.reduce_max(edges) + tf.keras.backend.epsilon())  # Normalize to 0-1\n",
    "    elif image_rank == 4:\n",
    "        # Shape is [batch_size, height, width, channels]\n",
    "        edges = tf.image.sobel_edges(image)     # Output shape: [batch_size, height, width, channels, 2]\n",
    "        edges = tf.sqrt(tf.reduce_sum(tf.square(edges), axis=-1))  # Shape: [batch_size, height, width, channels]\n",
    "        edges = edges / (tf.reduce_max(edges, axis=[1,2,3], keepdims=True) + tf.keras.backend.epsilon())  # Normalize to 0-1\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported image rank: {}\".format(image_rank))\n",
    "    return edges\n",
    "\n",
    "# Data generator with edge detection preprocessing\n",
    "def data_generator(image_dir, df, img_size, batch_size=16):\n",
    "    while True:\n",
    "        df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "        for start in range(0, len(df_shuffled), batch_size):\n",
    "            end = min(start + batch_size, len(df_shuffled))\n",
    "            batch_df = df_shuffled.iloc[start:end]\n",
    "\n",
    "            images = []\n",
    "            masks = []\n",
    "\n",
    "            for index, row in batch_df.iterrows():\n",
    "                img_id = row['ImageId']\n",
    "                img_path = os.path.join(image_dir, img_id + '.dcm')\n",
    "\n",
    "                dicom_data = pydicom.dcmread(img_path)\n",
    "                img = dicom_data.pixel_array\n",
    "\n",
    "                # Resize the original image\n",
    "                img_resized = cv2.resize(img, img_size)\n",
    "                img_resized = img_resized / 255.0  # Normalize image to range 0-1\n",
    "\n",
    "                # Apply Sobel edge detection\n",
    "                edge_img = sobel_edge_detection(tf.convert_to_tensor(img_resized, dtype=tf.float32))\n",
    "                edge_img = edge_img.numpy()  # Convert to numpy array\n",
    "\n",
    "                # Ensure edge_img has same shape as img_resized\n",
    "                if img_resized.shape != edge_img.shape:\n",
    "                    edge_img = cv2.resize(edge_img, (img_resized.shape[1], img_resized.shape[0]))\n",
    "\n",
    "                # Stack the resized original and edge-detected image\n",
    "                img_combined = np.stack([img_resized, edge_img], axis=-1)\n",
    "\n",
    "                # Check if there is a mask\n",
    "                if pd.isna(row['EncodedPixels']):\n",
    "                    mask = np.zeros(img_size, dtype=np.uint8)  # No pneumothorax, empty mask\n",
    "                else:\n",
    "                    mask = rle2mask(row['EncodedPixels'], dicom_data.Columns, dicom_data.Rows)\n",
    "                    mask = cv2.resize(mask, img_size, interpolation=cv2.INTER_NEAREST)\n",
    "                    mask = (mask > 127).astype(np.uint8)  # Binarize mask\n",
    "\n",
    "                images.append(img_combined)\n",
    "                masks.append(np.expand_dims(mask, axis=-1))  # Add channel dimension to the mask\n",
    "\n",
    "            yield np.array(images), np.array(masks)\n",
    "\n",
    "# Custom Metrics for Precision, Recall, F1, and Specificity\n",
    "def custom_precision(y_true, y_pred):\n",
    "    y_true = tf.cast(tf.round(y_true), 'float32')  # Ensure y_true is binary\n",
    "    y_pred = tf.round(y_pred)\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred)\n",
    "    predicted_positives = tf.reduce_sum(y_pred)\n",
    "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
    "    return precision\n",
    "\n",
    "def custom_recall(y_true, y_pred):\n",
    "    y_true = tf.cast(tf.round(y_true), 'float32')  # Ensure y_true is binary\n",
    "    y_pred = tf.round(y_pred)\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred)\n",
    "    possible_positives = tf.reduce_sum(y_true)\n",
    "    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
    "    return recall\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    precision = custom_precision(y_true, y_pred)\n",
    "    recall = custom_recall(y_true, y_pred)\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
    "    return f1\n",
    "\n",
    "def custom_specificity(y_true, y_pred):\n",
    "    y_true = tf.cast(tf.round(y_true), 'float32')  # Ensure y_true is binary\n",
    "    y_pred = tf.round(y_pred)\n",
    "    true_negatives = tf.reduce_sum((1 - y_true) * (1 - y_pred))\n",
    "    possible_negatives = tf.reduce_sum(1 - y_true)\n",
    "    specificity = true_negatives / (possible_negatives + tf.keras.backend.epsilon())\n",
    "    return specificity\n",
    "\n",
    "# Capsule Layer with Dynamic Routing\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def squash(vectors, axis=-1):\n",
    "    \"\"\"Squashing function to ensure output vectors' lengths are between 0 and 1\"\"\"\n",
    "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm + tf.keras.backend.epsilon())\n",
    "    return scale * vectors / tf.sqrt(s_squared_norm + tf.keras.backend.epsilon())\n",
    "\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    def __init__(self, num_capsules, dim_capsule, num_routing=3, **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsules = num_capsules\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.num_routing = num_routing\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=[input_shape[-1], self.num_capsules * self.dim_capsule],\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.reshape(inputs, [-1, inputs.shape[1] * inputs.shape[2], inputs.shape[3]])\n",
    "        u_hat = tf.einsum('...ij,jk->...ik', inputs, self.W)\n",
    "        u_hat = tf.reshape(u_hat, [-1, inputs.shape[1], self.num_capsules, self.dim_capsule])\n",
    "        \n",
    "        b = tf.zeros(shape=[tf.shape(inputs)[0], inputs.shape[1], self.num_capsules])\n",
    "        for i in range(self.num_routing):\n",
    "            c = tf.nn.softmax(b, axis=-1)\n",
    "            s = tf.reduce_sum(c[..., tf.newaxis] * u_hat, axis=1)\n",
    "            v = squash(s)\n",
    "            if i < self.num_routing - 1:\n",
    "                b += tf.reduce_sum(u_hat * v[:, tf.newaxis, :, :], axis=-1)\n",
    "        return v\n",
    "\n",
    "# Attention Gate (fixed shape mismatch)\n",
    "def attention_gate(x, g, inter_shape, upsample=False):\n",
    "    theta_x = tf.keras.layers.Conv2D(inter_shape, kernel_size=1, strides=1, padding='same')(x)\n",
    "    phi_g = tf.keras.layers.Conv2D(inter_shape, kernel_size=1, padding='same')(g)\n",
    "    \n",
    "    if upsample:\n",
    "        # Use Lambda layer to resize phi_g to match theta_x\n",
    "        phi_g = tf.keras.layers.Lambda(\n",
    "            lambda inputs: tf.image.resize(inputs[0], tf.shape(inputs[1])[1:3], method='bilinear'))([phi_g, theta_x])\n",
    "    \n",
    "    add_xg = tf.keras.layers.add([theta_x, phi_g])\n",
    "    relu_xg = tf.keras.layers.Activation('relu')(add_xg)\n",
    "    psi = tf.keras.layers.Conv2D(1, kernel_size=1, padding='same')(relu_xg)\n",
    "    sigmoid_xg = tf.keras.layers.Activation('sigmoid')(psi)\n",
    "    return tf.keras.layers.Multiply()([x, sigmoid_xg])\n",
    "\n",
    "# U-Net with Capsule Network Layers, Attention Mechanism, and Dynamic Routing\n",
    "def unet_capsule_model(input_size=(256, 256, 2)):  # 2-channel input (original + edge)\n",
    "    inputs = tf.keras.layers.Input(input_size)\n",
    "    \n",
    "    # Contracting Path with Capsules\n",
    "    c1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = CapsuleLayer(num_capsules=8, dim_capsule=16)(c1)\n",
    "    c1_flattened = tf.keras.layers.Flatten()(c1)\n",
    "    c1_reshaped = tf.keras.layers.Dense(256 * 256, activation='relu')(c1_flattened)\n",
    "    c1_reshaped = tf.keras.layers.Reshape((256, 256, 1))(c1_reshaped)\n",
    "    p1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c1_reshaped)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = CapsuleLayer(num_capsules=16, dim_capsule=32)(c2)\n",
    "    c2_flattened = tf.keras.layers.Flatten()(c2)\n",
    "    c2_reshaped = tf.keras.layers.Dense(128 * 128, activation='relu')(c2_flattened)\n",
    "    c2_reshaped = tf.keras.layers.Reshape((128, 128, 1))(c2_reshaped)\n",
    "    p2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c2_reshaped)\n",
    "    \n",
    "    c3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
    "    c3 = CapsuleLayer(num_capsules=32, dim_capsule=64)(c3)\n",
    "    c3_flattened = tf.keras.layers.Flatten()(c3)\n",
    "    c3_reshaped = tf.keras.layers.Dense(64 * 64, activation='relu')(c3_flattened)\n",
    "    c3_reshaped = tf.keras.layers.Reshape((64, 64, 1))(c3_reshaped)\n",
    "    p3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c3_reshaped)\n",
    "    \n",
    "    # Bottleneck\n",
    "    b = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(p3)\n",
    "    b = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(b)\n",
    "    \n",
    "    # Attention mechanism in expansive path\n",
    "    g1 = tf.keras.layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(b)\n",
    "    a1 = attention_gate(c3_reshaped, g1, 128, upsample=True)\n",
    "    u1 = tf.keras.layers.concatenate([g1, a1])\n",
    "    c4 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(u1)\n",
    "    c4 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(c4)\n",
    "    \n",
    "    g2 = tf.keras.layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(c4)\n",
    "    a2 = attention_gate(c2_reshaped, g2, 64, upsample=True)\n",
    "    u2 = tf.keras.layers.concatenate([g2, a2])\n",
    "    c5 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(u2)\n",
    "    c5 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(c5)\n",
    "    \n",
    "    g3 = tf.keras.layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(c5)\n",
    "    a3 = attention_gate(c1_reshaped, g3, 32, upsample=True)\n",
    "    u3 = tf.keras.layers.concatenate([g3, a3])\n",
    "    c6 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(u3)\n",
    "    c6 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(c6)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(c6)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Boundary Loss Function\n",
    "def boundary_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(tf.round(y_true), dtype='float32')  # Ensure y_true is binary\n",
    "    y_pred = tf.cast(y_pred, dtype='float32')\n",
    "\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    \n",
    "    # Dice Loss\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    dice_loss = 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n",
    "    \n",
    "    # Boundary Loss (difference between boundary of prediction and ground truth)\n",
    "    sobel_true = sobel_edge_detection(y_true)\n",
    "    sobel_pred = sobel_edge_detection(y_pred)\n",
    "    boundary_diff = tf.reduce_mean(tf.abs(sobel_true - sobel_pred))\n",
    "    \n",
    "    return dice_loss + boundary_diff\n",
    "\n",
    "# Custom callback to print more metrics at each batch in the exact format you requested\n",
    "class MetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.batch_counter = 1  # Initialize the batch counter\n",
    "    \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        \n",
    "        # Time formatting for current step\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        # Print the metrics with proper formatting\n",
    "        print(f\"{self.batch_counter}/723 ━━━━━━━━━━━━━━━━━━━━ {current_time} - 60s/step\")\n",
    "        print(f\"Accuracy: {accuracy:.4f} - Precision: {precision:.4f} - Recall: {recall:.4f} - Specificity: {specificity:.4f} - F1: {f1:.4f} - Loss: {loss:.4f}\\n\")\n",
    "        \n",
    "        # Increment batch counter\n",
    "        self.batch_counter += 1\n",
    "\n",
    "# Batch size for data generator\n",
    "batch_size = 16\n",
    "\n",
    "# Train generator and test generator\n",
    "train_generator = data_generator(train_image_dir, train_df, img_size, batch_size=batch_size)\n",
    "test_generator = data_generator(test_image_dir, test_df, img_size, batch_size=batch_size)\n",
    "\n",
    "# Model training and testing\n",
    "model = unet_capsule_model()\n",
    "model.compile(optimizer='adam', loss=boundary_loss, metrics=['accuracy', custom_precision, custom_recall, custom_f1, custom_specificity])\n",
    "\n",
    "# Train the model with the custom callback (verbose=0 to avoid duplicate output)\n",
    "history = model.fit(train_generator, steps_per_epoch=len(train_df) // batch_size, epochs=1,  # Train for 1 epoch\n",
    "                    validation_data=test_generator, validation_steps=len(test_df) // batch_size,\n",
    "                    callbacks=[MetricsCallback()], verbose=0)\n",
    "\n",
    "# Evaluate on the train set\n",
    "train_generator_eval = data_generator(train_image_dir, train_df, img_size, batch_size=batch_size)\n",
    "y_train_pred = model.predict(train_generator_eval, steps=len(train_df) // batch_size)\n",
    "y_train_true_list = []\n",
    "for _ in range(len(train_df) // batch_size):\n",
    "    _, masks = next(train_generator_eval)\n",
    "    y_train_true_list.append(masks)\n",
    "y_train_true = np.concatenate(y_train_true_list)\n",
    "y_train_pred = (y_train_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for training\n",
    "conf_matrix_train = confusion_matrix(y_train_true.flatten(), y_train_pred.flatten())\n",
    "sns.heatmap(conf_matrix_train, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix for Train\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_generator_eval = data_generator(test_image_dir, test_df, img_size, batch_size=batch_size)\n",
    "y_test_pred = model.predict(test_generator_eval, steps=len(test_df) // batch_size)\n",
    "y_test_true_list = []\n",
    "for _ in range(len(test_df) // batch_size):\n",
    "    _, masks = next(test_generator_eval)\n",
    "    y_test_true_list.append(masks)\n",
    "y_test_true = np.concatenate(y_test_true_list)\n",
    "y_test_pred = (y_test_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for testing\n",
    "conf_matrix_test = confusion_matrix(y_test_true.flatten(), y_test_pred.flatten())\n",
    "sns.heatmap(conf_matrix_test, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix for Test\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization: Show input image, true mask, and predicted mask for a few samples for both train and test\n",
    "def visualize_predictions(generator, true_masks, pred_masks, title):\n",
    "    for i in range(3):  # Visualize first 3 predictions\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        X_batch, _ = next(generator)\n",
    "        X = X_batch[i]\n",
    "        \n",
    "        ax[0].imshow(X[:, :, 0].squeeze(), cmap='gray')\n",
    "        ax[0].set_title('Input Image')\n",
    "\n",
    "        ax[1].imshow(true_masks[i].squeeze(), cmap='gray')\n",
    "        ax[1].set_title('True Mask')\n",
    "\n",
    "        ax[2].imshow(pred_masks[i].squeeze(), cmap='gray')\n",
    "        ax[2].set_title('Predicted Mask')\n",
    "\n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "# Visualize predictions for training set\n",
    "train_generator_eval = data_generator(train_image_dir, train_df, img_size, batch_size=batch_size)\n",
    "visualize_predictions(train_generator_eval, y_train_true, y_train_pred, \"Train Set Predictions\")\n",
    "\n",
    "# Visualize predictions for testing set\n",
    "test_generator_eval = data_generator(test_image_dir, test_df, img_size, batch_size=batch_size)\n",
    "visualize_predictions(test_generator_eval, y_test_true, y_test_pred, \"Test Set Predictions\")\n",
    "\n",
    "# Performance report for training set\n",
    "train_accuracy = accuracy_score(y_train_true.flatten(), y_train_pred.flatten())\n",
    "train_recall = recall_score(y_train_true.flatten(), y_train_pred.flatten())\n",
    "train_precision = precision_score(y_train_true.flatten(), y_train_pred.flatten())\n",
    "train_f1 = f1_score(y_train_true.flatten(), y_train_pred.flatten())\n",
    "train_tn, train_fp, train_fn, train_tp = confusion_matrix(y_train_true.flatten(), y_train_pred.flatten()).ravel()\n",
    "train_specificity = train_tn / (train_tn + train_fp)\n",
    "\n",
    "print(f'Training Set Results:')\n",
    "print(f'Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Recall (Sensitivity): {train_recall:.4f}')\n",
    "print(f'Precision: {train_precision:.4f}')\n",
    "print(f'F1 Score: {train_f1:.4f}')\n",
    "print(f'Specificity: {train_specificity:.4f}')\n",
    "\n",
    "# Performance report for testing set\n",
    "test_accuracy = accuracy_score(y_test_true.flatten(), y_test_pred.flatten())\n",
    "test_recall = recall_score(y_test_true.flatten(), y_test_pred.flatten())\n",
    "test_precision = precision_score(y_test_true.flatten(), y_test_pred.flatten())\n",
    "test_f1 = f1_score(y_test_true.flatten(), y_test_pred.flatten())\n",
    "test_tn, test_fp, test_fn, test_tp = confusion_matrix(y_test_true.flatten(), y_test_pred.flatten()).ravel()\n",
    "test_specificity = test_tn / (test_tn + test_fp)\n",
    "\n",
    "print(f'Testing Set Results:')\n",
    "print(f'Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Recall (Sensitivity): {test_recall:.4f}')\n",
    "print(f'Precision: {test_precision:.4f}')\n",
    "print(f'F1 Score: {test_f1:.4f}')\n",
    "print(f'Specificity: {test_specificity:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d02f4-7883-47ab-a8d5-4515bde9522b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474044d0-8a90-489d-9488-0185e3c34fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49acb10a-8254-470f-8db3-5036a1ca0926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "300267b4-b2ad-454d-8acb-182fa4166086",
   "metadata": {},
   "source": [
    "* Precsion is not promissing!\n",
    "* Trying again with the above items!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e8e2a-bab2-40b4-b647-14c173bebfbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777b102-6285-46c6-b6ee-d551e9530f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd119a2-b25c-4066-8837-f856cd138ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c6cdd-836a-4dfa-950e-ddb4ce7e17ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6da3ecc-3e12-4ce3-a615-8c47c014db46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc1428-246f-47df-8df1-44361af9b8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f204d347-ab7f-44fd-92e0-c46b1a876e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cbfdcc-7b3f-468b-b16e-cf534fdfc9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
