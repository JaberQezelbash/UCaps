{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21220fe-e4c3-41a5-bc62-e3c987b60087",
   "metadata": {},
   "source": [
    "### Without C.V\n",
    "* Still takes 17 hours to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a574546-e2d4-4e6b-870b-e21e24aff581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jaber\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m  1/723\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:17:56\u001b[0m 86s/step - accuracy: 0.2112 - loss: 1.6889"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Directories for SIIM-ACR Pneumothorax Segmentation dataset\n",
    "train_image_dir = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\SIIM-ACR Pneumothorax Segmentation\\archive\\pneumothorax\\dicom-images-train'\n",
    "test_image_dir = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\SIIM-ACR Pneumothorax Segmentation\\archive\\pneumothorax\\dicom-images-test'\n",
    "train_csv_path = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\SIIM-ACR Pneumothorax Segmentation\\archive\\pneumothorax\\train-rle.csv'\n",
    "\n",
    "img_size = (256, 256)\n",
    "\n",
    "# Load the combined CSV that contains both train and test mask information\n",
    "combined_df = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Split into training and test sets based on the availability of the image files\n",
    "train_df = combined_df[combined_df['ImageId'].apply(lambda x: os.path.exists(os.path.join(train_image_dir, x + '.dcm')))]\n",
    "test_df = combined_df[combined_df['ImageId'].apply(lambda x: os.path.exists(os.path.join(test_image_dir, x + '.dcm')))]\n",
    "\n",
    "# Define the rle2mask function here instead of importing from mask_functions\n",
    "def rle2mask(rle, width, height):\n",
    "    mask = np.zeros(width * height, dtype=np.uint8)\n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "    current_position = 0\n",
    "    for start, length in zip(starts, lengths):\n",
    "        current_position += start\n",
    "        mask[current_position:current_position + length] = 255\n",
    "        current_position += length\n",
    "    return mask.reshape((height, width))\n",
    "\n",
    "# Data generator to load data in batches\n",
    "def data_generator(image_dir, df, img_size, batch_size=16):\n",
    "    while True:\n",
    "        df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "        for start in range(0, len(df_shuffled), batch_size):\n",
    "            end = min(start + batch_size, len(df_shuffled))\n",
    "            batch_df = df_shuffled.iloc[start:end]\n",
    "\n",
    "            images = []\n",
    "            masks = []\n",
    "\n",
    "            for index, row in batch_df.iterrows():\n",
    "                img_id = row['ImageId']\n",
    "                img_path = os.path.join(image_dir, img_id + '.dcm')\n",
    "\n",
    "                dicom_data = pydicom.dcmread(img_path)\n",
    "                img = dicom_data.pixel_array\n",
    "\n",
    "                img = cv2.resize(img, img_size)\n",
    "                img = img / 255.0  # Normalize image to range 0-1\n",
    "\n",
    "                # Check if there is a mask\n",
    "                if pd.isna(row['EncodedPixels']):\n",
    "                    mask = np.zeros(img_size)  # No pneumothorax, empty mask\n",
    "                else:\n",
    "                    mask = rle2mask(row['EncodedPixels'], dicom_data.Rows, dicom_data.Columns)\n",
    "                    mask = cv2.resize(mask, img_size)\n",
    "                    mask = mask / 255.0  # Normalize mask to range 0-1\n",
    "\n",
    "                images.append(np.expand_dims(img, axis=-1))  # Add channel dimension to the image\n",
    "                masks.append(np.expand_dims(mask, axis=-1))  # Add channel dimension to the mask\n",
    "\n",
    "            yield np.array(images), np.array(masks)\n",
    "\n",
    "# Capsule Layer with Dynamic Routing\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def squash(vectors, axis=-1):\n",
    "    \"\"\"Squashing function to ensure output vectors' lengths are between 0 and 1\"\"\"\n",
    "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + tf.keras.backend.epsilon())\n",
    "    return scale * vectors\n",
    "\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    def __init__(self, num_capsules, dim_capsule, num_routing=3, **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsules = num_capsules\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.num_routing = num_routing\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=[input_shape[-1], self.num_capsules * self.dim_capsule],\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.reshape(inputs, [-1, inputs.shape[1] * inputs.shape[2], inputs.shape[3]])\n",
    "        u_hat = tf.einsum('...ij,jk->...ik', inputs, self.W)\n",
    "        u_hat = tf.reshape(u_hat, [-1, inputs.shape[1], self.num_capsules, self.dim_capsule])\n",
    "        \n",
    "        b = tf.zeros(shape=[tf.shape(inputs)[0], inputs.shape[1], self.num_capsules])\n",
    "        for i in range(self.num_routing):\n",
    "            c = tf.nn.softmax(b, axis=-1)\n",
    "            s = tf.reduce_sum(c[..., tf.newaxis] * u_hat, axis=1)\n",
    "            v = squash(s)\n",
    "            if i < self.num_routing - 1:\n",
    "                b += tf.reduce_sum(u_hat * v[:, tf.newaxis, :, :], axis=-1)\n",
    "        return v\n",
    "\n",
    "# U-Net with Capsule Network Layers and Dynamic Routing\n",
    "def unet_capsule_model(input_size=(256, 256, 1)):\n",
    "    inputs = tf.keras.layers.Input(input_size)\n",
    "    \n",
    "    # Contracting Path with Capsules\n",
    "    c1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = CapsuleLayer(num_capsules=8, dim_capsule=16)(c1)\n",
    "    c1_flattened = tf.keras.layers.Flatten()(c1)  # Flatten the capsule output\n",
    "    c1_reshaped = tf.keras.layers.Dense(256*256, activation='relu')(c1_flattened)  # Fully connected layer to reshape\n",
    "    c1_reshaped = tf.keras.layers.Reshape((256, 256, 1))(c1_reshaped)  # Reshape to 4D\n",
    "    p1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c1_reshaped)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = CapsuleLayer(num_capsules=16, dim_capsule=32)(c2)\n",
    "    c2_flattened = tf.keras.layers.Flatten()(c2)\n",
    "    c2_reshaped = tf.keras.layers.Dense(128*128, activation='relu')(c2_flattened)\n",
    "    c2_reshaped = tf.keras.layers.Reshape((128, 128, 1))(c2_reshaped)\n",
    "    p2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c2_reshaped)\n",
    "    \n",
    "    c3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
    "    c3 = CapsuleLayer(num_capsules=32, dim_capsule=64)(c3)\n",
    "    c3_flattened = tf.keras.layers.Flatten()(c3)\n",
    "    c3_reshaped = tf.keras.layers.Dense(64*64, activation='relu')(c3_flattened)\n",
    "    c3_reshaped = tf.keras.layers.Reshape((64, 64, 1))(c3_reshaped)\n",
    "    p3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c3_reshaped)\n",
    "    \n",
    "    # Bottleneck\n",
    "    b = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(p3)\n",
    "    b = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(b)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u1 = tf.keras.layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(b)\n",
    "    u1 = tf.keras.layers.concatenate([u1, c3_reshaped])\n",
    "    c4 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(u1)\n",
    "    c4 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(c4)\n",
    "    \n",
    "    u2 = tf.keras.layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(c4)\n",
    "    u2 = tf.keras.layers.concatenate([u2, c2_reshaped])\n",
    "    c5 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(u2)\n",
    "    c5 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(c5)\n",
    "    \n",
    "    u3 = tf.keras.layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(c5)\n",
    "    u3 = tf.keras.layers.concatenate([u3, c1_reshaped])\n",
    "    c6 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(u3)\n",
    "    c6 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(c6)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(c6)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Dice and Binary Crossentropy combined loss function\n",
    "def combined_dice_bce_loss(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    \n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    dice_loss = 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n",
    "    \n",
    "    bce_loss = tf.keras.losses.binary_crossentropy(y_true_f, y_pred_f)\n",
    "    \n",
    "    return dice_loss + bce_loss\n",
    "\n",
    "# Learning rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch > 10:\n",
    "        lr = lr * 0.5  # Reduce learning rate after 10 epochs\n",
    "    return lr\n",
    "\n",
    "# Early stopping callback to avoid overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Batch size for data generator\n",
    "batch_size = 16\n",
    "\n",
    "# Train generator and test generator\n",
    "train_generator = data_generator(train_image_dir, train_df, img_size, batch_size=batch_size)\n",
    "test_generator = data_generator(test_image_dir, test_df, img_size, batch_size=batch_size)\n",
    "\n",
    "# Model training and testing\n",
    "model = unet_capsule_model()\n",
    "model.compile(optimizer='adam', loss=combined_dice_bce_loss, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, steps_per_epoch=len(train_df) // batch_size, epochs=50, \n",
    "                    validation_data=test_generator, validation_steps=len(test_df) // batch_size, \n",
    "                    callbacks=[early_stopping, lr_callback], verbose=1)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = model.predict(test_generator, steps=len(test_df) // batch_size)\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred > threshold).astype(np.uint8)\n",
    "y_test_binary = np.array([mask for _, mask in test_generator]).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test_binary.flatten(), y_pred.flatten())\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization: Show input image, true mask, and predicted mask for a few samples\n",
    "for i in range(3):  # Visualize first 3 predictions\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    X_test = next(test_generator)[0]\n",
    "    \n",
    "    ax[0].imshow(X_test[i].squeeze(), cmap='gray')\n",
    "    ax[0].set_title('Input Image')\n",
    "    \n",
    "    ax[1].imshow(y_test_binary[i].squeeze(), cmap='gray')\n",
    "    ax[1].set_title('True Mask')\n",
    "    \n",
    "    ax[2].imshow(y_pred[i].squeeze(), cmap='gray')\n",
    "    ax[2].set_title('Predicted Mask')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Performance report\n",
    "accuracy = accuracy_score(y_test_binary.flatten(), y_pred.flatten())\n",
    "recall = recall_score(y_test_binary.flatten(), y_pred.flatten())\n",
    "precision = precision_score(y_test_binary.flatten(), y_pred.flatten())\n",
    "f1 = f1_score(y_test_binary.flatten(), y_pred.flatten())\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_binary.flatten(), y_pred.flatten()).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Recall (Sensitivity): {recall:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27393166-fc48-497c-bf89-a9e33246c491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a91f3d4-eca5-4e73-ae30-1e44ddb24e0c",
   "metadata": {},
   "source": [
    "### Train only on One Epoch to reduce runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0da0fd4-c953-4ad1-af50-2e239608db7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jaber\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:192: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\u001b[1m642/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:14:39\u001b[0m 55s/step - accuracy: 0.9950 - loss: 1.0624"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Directories for SIIM-ACR Pneumothorax Segmentation dataset\n",
    "train_image_dir = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\SIIM-ACR Pneumothorax Segmentation\\archive\\pneumothorax\\dicom-images-train'\n",
    "test_image_dir = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\SIIM-ACR Pneumothorax Segmentation\\archive\\pneumothorax\\dicom-images-test'\n",
    "train_csv_path = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\SIIM-ACR Pneumothorax Segmentation\\archive\\pneumothorax\\train-rle.csv'\n",
    "\n",
    "img_size = (256, 256)\n",
    "\n",
    "# Load the combined CSV that contains both train and test mask information\n",
    "combined_df = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Split into training and test sets based on the availability of the image files\n",
    "train_df = combined_df[combined_df['ImageId'].apply(lambda x: os.path.exists(os.path.join(train_image_dir, x + '.dcm')))]\n",
    "test_df = combined_df[combined_df['ImageId'].apply(lambda x: os.path.exists(os.path.join(test_image_dir, x + '.dcm')))]\n",
    "\n",
    "# Define the rle2mask function here instead of importing from mask_functions\n",
    "def rle2mask(rle, width, height):\n",
    "    mask = np.zeros(width * height, dtype=np.uint8)\n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "    current_position = 0\n",
    "    for start, length in zip(starts, lengths):\n",
    "        current_position += start\n",
    "        mask[current_position:current_position + length] = 255\n",
    "        current_position += length\n",
    "    return mask.reshape((height, width))\n",
    "\n",
    "# Data generator to load data in batches\n",
    "def data_generator(image_dir, df, img_size, batch_size=16):\n",
    "    while True:\n",
    "        df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "        for start in range(0, len(df_shuffled), batch_size):\n",
    "            end = min(start + batch_size, len(df_shuffled))\n",
    "            batch_df = df_shuffled.iloc[start:end]\n",
    "\n",
    "            images = []\n",
    "            masks = []\n",
    "\n",
    "            for index, row in batch_df.iterrows():\n",
    "                img_id = row['ImageId']\n",
    "                img_path = os.path.join(image_dir, img_id + '.dcm')\n",
    "\n",
    "                dicom_data = pydicom.dcmread(img_path)\n",
    "                img = dicom_data.pixel_array\n",
    "\n",
    "                img = cv2.resize(img, img_size)\n",
    "                img = img / 255.0  # Normalize image to range 0-1\n",
    "\n",
    "                # Check if there is a mask\n",
    "                if pd.isna(row['EncodedPixels']):\n",
    "                    mask = np.zeros(img_size)  # No pneumothorax, empty mask\n",
    "                else:\n",
    "                    mask = rle2mask(row['EncodedPixels'], dicom_data.Rows, dicom_data.Columns)\n",
    "                    mask = cv2.resize(mask, img_size)\n",
    "                    mask = mask / 255.0  # Normalize mask to range 0-1\n",
    "\n",
    "                images.append(np.expand_dims(img, axis=-1))  # Add channel dimension to the image\n",
    "                masks.append(np.expand_dims(mask, axis=-1))  # Add channel dimension to the mask\n",
    "\n",
    "            yield np.array(images), np.array(masks)\n",
    "\n",
    "# Capsule Layer with Dynamic Routing\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def squash(vectors, axis=-1):\n",
    "    \"\"\"Squashing function to ensure output vectors' lengths are between 0 and 1\"\"\"\n",
    "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + tf.keras.backend.epsilon())\n",
    "    return scale * vectors\n",
    "\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    def __init__(self, num_capsules, dim_capsule, num_routing=3, **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsules = num_capsules\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.num_routing = num_routing\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=[input_shape[-1], self.num_capsules * self.dim_capsule],\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.reshape(inputs, [-1, inputs.shape[1] * inputs.shape[2], inputs.shape[3]])\n",
    "        u_hat = tf.einsum('...ij,jk->...ik', inputs, self.W)\n",
    "        u_hat = tf.reshape(u_hat, [-1, inputs.shape[1], self.num_capsules, self.dim_capsule])\n",
    "        \n",
    "        b = tf.zeros(shape=[tf.shape(inputs)[0], inputs.shape[1], self.num_capsules])\n",
    "        for i in range(self.num_routing):\n",
    "            c = tf.nn.softmax(b, axis=-1)\n",
    "            s = tf.reduce_sum(c[..., tf.newaxis] * u_hat, axis=1)\n",
    "            v = squash(s)\n",
    "            if i < self.num_routing - 1:\n",
    "                b += tf.reduce_sum(u_hat * v[:, tf.newaxis, :, :], axis=-1)\n",
    "        return v\n",
    "\n",
    "# U-Net with Capsule Network Layers and Dynamic Routing\n",
    "def unet_capsule_model(input_size=(256, 256, 1)):\n",
    "    inputs = tf.keras.layers.Input(input_size)\n",
    "    \n",
    "    # Contracting Path with Capsules\n",
    "    c1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = CapsuleLayer(num_capsules=8, dim_capsule=16)(c1)\n",
    "    c1_flattened = tf.keras.layers.Flatten()(c1)  # Flatten the capsule output\n",
    "    c1_reshaped = tf.keras.layers.Dense(256*256, activation='relu')(c1_flattened)  # Fully connected layer to reshape\n",
    "    c1_reshaped = tf.keras.layers.Reshape((256, 256, 1))(c1_reshaped)  # Reshape to 4D\n",
    "    p1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c1_reshaped)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = CapsuleLayer(num_capsules=16, dim_capsule=32)(c2)\n",
    "    c2_flattened = tf.keras.layers.Flatten()(c2)\n",
    "    c2_reshaped = tf.keras.layers.Dense(128*128, activation='relu')(c2_flattened)\n",
    "    c2_reshaped = tf.keras.layers.Reshape((128, 128, 1))(c2_reshaped)\n",
    "    p2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c2_reshaped)\n",
    "    \n",
    "    c3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
    "    c3 = CapsuleLayer(num_capsules=32, dim_capsule=64)(c3)\n",
    "    c3_flattened = tf.keras.layers.Flatten()(c3)\n",
    "    c3_reshaped = tf.keras.layers.Dense(64*64, activation='relu')(c3_flattened)\n",
    "    c3_reshaped = tf.keras.layers.Reshape((64, 64, 1))(c3_reshaped)\n",
    "    p3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c3_reshaped)\n",
    "    \n",
    "    # Bottleneck\n",
    "    b = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(p3)\n",
    "    b = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(b)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u1 = tf.keras.layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(b)\n",
    "    u1 = tf.keras.layers.concatenate([u1, c3_reshaped])\n",
    "    c4 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(u1)\n",
    "    c4 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(c4)\n",
    "    \n",
    "    u2 = tf.keras.layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(c4)\n",
    "    u2 = tf.keras.layers.concatenate([u2, c2_reshaped])\n",
    "    c5 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(u2)\n",
    "    c5 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(c5)\n",
    "    \n",
    "    u3 = tf.keras.layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(c5)\n",
    "    u3 = tf.keras.layers.concatenate([u3, c1_reshaped])\n",
    "    c6 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(u3)\n",
    "    c6 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(c6)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(c6)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Dice and Binary Crossentropy combined loss function\n",
    "def combined_dice_bce_loss(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    \n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    dice_loss = 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n",
    "    \n",
    "    bce_loss = tf.keras.losses.binary_crossentropy(y_true_f, y_pred_f)\n",
    "    \n",
    "    return dice_loss + bce_loss\n",
    "\n",
    "# Batch size for data generator\n",
    "batch_size = 16\n",
    "\n",
    "# Train generator and test generator\n",
    "train_generator = data_generator(train_image_dir, train_df, img_size, batch_size=batch_size)\n",
    "test_generator = data_generator(test_image_dir, test_df, img_size, batch_size=batch_size)\n",
    "\n",
    "# Model training and testing\n",
    "model = unet_capsule_model()\n",
    "model.compile(optimizer='adam', loss=combined_dice_bce_loss, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, steps_per_epoch=len(train_df) // batch_size, epochs=1,  # Train for 1 epoch\n",
    "                    validation_data=test_generator, validation_steps=len(test_df) // batch_size, \n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = model.predict(test_generator, steps=len(test_df) // batch_size)\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred > threshold).astype(np.uint8)\n",
    "y_test_binary = np.array([mask for _, mask in test_generator]).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test_binary.flatten(), y_pred.flatten())\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization: Show input image, true mask, and predicted mask for a few samples\n",
    "for i in range(3):  # Visualize first 3 predictions\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    X_test = next(test_generator)[0]\n",
    "    \n",
    "    ax[0].imshow(X_test[i].squeeze(), cmap='gray')\n",
    "    ax[0].set_title('Input Image')\n",
    "    \n",
    "    ax[1].imshow(y_test_binary[i].squeeze(), cmap='gray')\n",
    "    ax[1].set_title('True Mask')\n",
    "    \n",
    "    ax[2].imshow(y_pred[i].squeeze(), cmap='gray')\n",
    "    ax[2].set_title('Predicted Mask')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Performance report\n",
    "accuracy = accuracy_score(y_test_binary.flatten(), y_pred.flatten())\n",
    "recall = recall_score(y_test_binary.flatten(), y_pred.flatten())\n",
    "precision = precision_score(y_test_binary.flatten(), y_pred.flatten())\n",
    "f1 = f1_score(y_test_binary.flatten(), y_pred.flatten())\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_binary.flatten(), y_pred.flatten()).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Recall (Sensitivity): {recall:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299f0ed-1340-46f8-b3c2-7d6f5abe3e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
